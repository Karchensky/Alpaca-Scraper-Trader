{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpaca Trading Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "from alpaca_trade_api.rest import TimeFrame, TimeFrameUnit\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import ta\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class AlpacaTradingBot:\n",
    "    def __init__(self, keys_file_path='alpaca_keys.txt', base_url='https://paper-api.alpaca.markets', database_path=r'D:\\Scripts\\alpaca\\alpaca_algo_trading\\alpaca_data.db'):\n",
    "        with open(keys_file_path, 'r') as file:\n",
    "            self.api_key = file.readline().strip()\n",
    "            self.api_secret = file.readline().strip()\n",
    "        self.base_url = base_url\n",
    "        self.api = tradeapi.REST(self.api_key, self.api_secret, base_url=base_url)\n",
    "        self.database_path = database_path\n",
    "\n",
    "\n",
    "    def download_bar_data(self, stock, timeframe, start_date, end_date):\n",
    "        all_data = []\n",
    "\n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            # Get data for the current day\n",
    "            bars = self.api.get_bars(stock, timeframe, start=current_date, end=current_date, limit=1000).df\n",
    "            if bars.empty:\n",
    "                continue\n",
    "\n",
    "            bars['symbol'] = stock  # Add the stock symbol column\n",
    "            all_data.append(bars)\n",
    "\n",
    "            # Move to the next day\n",
    "            current_date = (datetime.strptime(current_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        if all_data:\n",
    "            combined_data = pd.concat(all_data)\n",
    "            combined_data = combined_data.reset_index()  # Ensure the index is reset to have 'timestamp' as a column\n",
    "            return combined_data[['symbol'] + [col for col in combined_data.columns if col != 'symbol']]\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    # This method calculates various indicators on a dataframe\n",
    "    def calculate_indicators(self, stock_data):\n",
    "        stock_data['rsi'] = ta.momentum.rsi(stock_data['close'], window=14)\n",
    "        stock_data['sma_50'] = ta.trend.sma_indicator(stock_data['close'], window=50)\n",
    "        stock_data['sma_200'] = ta.trend.sma_indicator(stock_data['close'], window=200)\n",
    "        stock_data['bollinger_hband'] = ta.volatility.bollinger_hband(stock_data['close'], window=20, window_dev=2)\n",
    "        stock_data['bollinger_lband'] = ta.volatility.bollinger_lband(stock_data['close'], window=20, window_dev=2)\n",
    "        return stock_data\n",
    "\n",
    "    # This method executes a SQL statement against our database.\n",
    "    def db_write(self, sql_statement):\n",
    "        db_path = self.database_path\n",
    "\n",
    "        # Connect to the database & create a cursor object\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Execute the SQL statement\n",
    "        cur.execute(sql_statement)\n",
    "\n",
    "        # Commit the changes & close the connection\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "    # This method appends records to our database.\n",
    "    def db_append(self, table_name, data_frame):\n",
    "        db_path = self.database_path\n",
    "\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "\n",
    "        # Append our dataframe into our table\n",
    "        data_frame.to_sql(table_name, conn, schema='main', if_exists='append', index=False)\n",
    "\n",
    "        # Commit the changes & close the connection\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "    # Modification of db_append that checks primary key & ensures we aren't inserting a duplicate value\n",
    "    def db_append_no_duplicates(self, table_name, data_frame):\n",
    "        db_path = self.database_path\n",
    "\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "\n",
    "        # Get existing primary keys from the table\n",
    "        existing_keys_query = f\"SELECT PRIMARY_KEY FROM {table_name}\"\n",
    "        existing_keys = pd.read_sql(existing_keys_query, conn)['PRIMARY_KEY'].tolist()\n",
    "\n",
    "        # Filter out rows with primary keys that already exist in the table\n",
    "        data_frame_new_records = data_frame[~data_frame['PRIMARY_KEY'].isin(existing_keys)]\n",
    "\n",
    "        # Append only the new rows into our table\n",
    "        data_frame_new_records.to_sql(table_name, conn, schema='main', if_exists='append', index=False)\n",
    "\n",
    "        # Commit the changes & close the connection\n",
    "        conn.commit()\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema DDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schema DDL\n",
    "atb = AlpacaTradingBot()\n",
    "\n",
    "# This table will house the raw schedule\n",
    "sql_statement = atb.db_write('''DROP TABLE IF EXISTS STG_SYMBOL_DATA''')\n",
    "sql_statement = atb.db_write('''CREATE TABLE IF NOT EXISTS STG_SYMBOL_DATA (\n",
    "    SYMBOL                  TEXT        PRIMARY_KEY,\n",
    "    TIMESTAMP               TIMESTAMP   PRIMARY_KEY,\n",
    "    CLOSE                   DECIMAL,\n",
    "    HIGH                    DECIMAL,\n",
    "    LOW                     DECIMAL,\n",
    "    TRADE_COUNT             INTEGER,\n",
    "    OPEN                    DECIMAL,\n",
    "    VOLUME                  INTEGER,\n",
    "    VWAP                    DECIMAL\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/SPY/bars 3 more time(s)...\n"
     ]
    }
   ],
   "source": [
    "atb = AlpacaTradingBot()\n",
    "\n",
    "# Define the list of stocks\n",
    "stocks = [\"SPY\"]\n",
    "\n",
    "# Define the time range for historical data\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2020-12-31\"\n",
    "# end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Download historical data\n",
    "data = {}\n",
    "for stock in stocks:\n",
    "    stock_data = atb.download_bar_data(stock, TimeFrame(5, TimeFrameUnit.Minute), start_date, end_date)\n",
    "    data[stock] = stock_data\n",
    "\n",
    "# Store data locally\n",
    "for stock, stock_data in data.items():\n",
    "    atb.db_append_no_duplicates('STG_SYMBOL_DATA', stock_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
